{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " # 梯度下降\n",
    "- 挑选一个初始值\n",
    "- 重复迭代参数t\n",
    "    $$\n",
    "    w_t = w_{t-1} - \\eta \\frac{\\partial l}{\\partial w_{t-1}}\n",
    "    $$\n",
    "    - 沿着梯度方向将增加**损失函数**的值（所以要沿着梯度的反方向下降）\n",
    "    - 学习率$\\eta$：步长的超参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 小批量随机梯度下降\n",
    "- 为什么要采用小批量？\n",
    "- 为什么b不能太大？\n",
    "- 为什么b不能太小？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 总结\n",
    "- 梯度下降通过不断沿着**反**梯度方向更新参数求解\n",
    "- 小批量随机梯度下降是深度学习默认的求解算法\n",
    "- 两个重要的超参数\n",
    "    - 批量大小\n",
    "    - 学习率"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}